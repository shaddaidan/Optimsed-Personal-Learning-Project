{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718a3cf8",
   "metadata": {},
   "source": [
    "## VERSION 6: now we are breaking into little part and putting it together to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1285245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the first portion of the code multi agent system and it works.\n",
    "\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup DeepSeek client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_followup_question(learning_goal):\n",
    "    prompt = f\"\"\"You are a motivational learning coach. A learner just said they want to learn: \"{learning_goal}\".\n",
    "\n",
    "Generate one open-ended, thoughtful question that will help them expand deeply on their personal motivation, challenges, or relationship to this topic. Be emotionally engaging and not too abstract.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        print(\"âœ… DeepSeek response received.\")\n",
    "        print(\"ðŸ”§ FULL RESPONSE:\", response)\n",
    "\n",
    "        content = response.choices[0].message.content.strip() if response.choices else \"\"\n",
    "        if not content:\n",
    "            print(\"âš ï¸ Empty content. Using fallback.\")\n",
    "            content = \"What does writing mean to you personally, and how do you want it to impact your future?\"\n",
    "\n",
    "        return content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ DeepSeek generation failed: {e}\")\n",
    "        return \"What inspires your desire to write, and what do you hope to express through it?\"\n",
    "\n",
    "\n",
    "def agent_one():\n",
    "    print(\"ðŸŽ¯ Welcome to the Adaptive Learning System (Prototype Agent 1)\")\n",
    "    learning_goal = input(\"ðŸ§  What are you trying to learn today?\\n> \")\n",
    "\n",
    "    # Generate personalized follow-up\n",
    "    followup_question = generate_followup_question(learning_goal)\n",
    "    print(f\"\\nðŸ” Reflect on this:\\n{followup_question}\\n\")\n",
    "\n",
    "    # Time response (to evaluate latency later)\n",
    "    start_time = time.time()\n",
    "    user_response = input(\"âœï¸ Your response:\\n> \")\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_taken = round(end_time - start_time, 2)\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    print(\"\\nðŸ•’ Time to respond:\", time_taken, \"seconds\")\n",
    "    print(\"ðŸ—“ï¸ Timestamp:\", timestamp)\n",
    "\n",
    "    return {\n",
    "        \"learning_goal\": learning_goal,\n",
    "        \"followup_question\": followup_question,\n",
    "        \"response\": user_response,\n",
    "        \"time_taken\": time_taken,\n",
    "        \"timestamp\": timestamp\n",
    "    }\n",
    "\n",
    "# Run prototype\n",
    "if __name__ == \"__main__\":\n",
    "    result = agent_one()\n",
    "    print(\"\\nâœ… DATA CAPTURED:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e9648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup DeepSeek client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_followup_question(learning_goal):\n",
    "    prompt = f\"\"\"You are a motivational learning coach. A learner just said they want to learn: \"{learning_goal}\".\n",
    "\n",
    "Generate one open-ended, thoughtful question that will help them expand deeply on their personal motivation, challenges, or relationship to this topic. Be emotionally engaging and not too abstract.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        print(\"âœ… DeepSeek response received.\")\n",
    "        print(\"ðŸ”§ FULL RESPONSE:\", response)\n",
    "\n",
    "        content = response.choices[0].message.content.strip() if response.choices else \"\"\n",
    "        if not content:\n",
    "            print(\"âš ï¸ Empty content. Using fallback.\")\n",
    "            content = \"What does writing mean to you personally, and how do you want it to impact your future?\"\n",
    "\n",
    "        return content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ DeepSeek generation failed: {e}\")\n",
    "        return \"What inspires your desire to write, and what do you hope to express through it?\"\n",
    "\n",
    "\n",
    "def agent_one():\n",
    "    print(\"ðŸŽ¯ Welcome to the Adaptive Learning System (Prototype Agent 1)\")\n",
    "    learning_goal = input(\"ðŸ§  What are you trying to learn today?\\n> \")\n",
    "\n",
    "    # Generate personalized follow-up\n",
    "    followup_question = generate_followup_question(learning_goal)\n",
    "    print(f\"\\nðŸ” Reflect on this:\\n{followup_question}\\n\")\n",
    "\n",
    "    # Time response (to evaluate latency later)\n",
    "    start_time = time.time()\n",
    "    user_response = input(\"âœï¸ Your response:\\n> \")\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_taken = round(end_time - start_time, 2)\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    print(\"\\nðŸ•’ Time to respond:\", time_taken, \"seconds\")\n",
    "    print(\"ðŸ—“ï¸ Timestamp:\", timestamp)\n",
    "\n",
    "    return {\n",
    "        \"learning_goal\": learning_goal,\n",
    "        \"followup_question\": followup_question,\n",
    "        \"response\": user_response,\n",
    "        \"time_taken\": time_taken,\n",
    "        \"timestamp\": timestamp\n",
    "    }\n",
    "\n",
    "# Run prototype\n",
    "if __name__ == \"__main__\":\n",
    "    result = agent_one()\n",
    "    print(\"\\nâœ… DATA CAPTURED:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "def analyze_response_gemma(response_text, time_taken, session_num, goal, history=None):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert language analyst. A learner wants to improve at: \"{goal}\".\n",
    "\n",
    "Here is their reflective response:\n",
    "\"{response_text}\"\n",
    "\n",
    "Evaluate on a 0â€“1 scale:\n",
    "1. Conceptual Vocabulary (depth, variety, originality)\n",
    "2. Clarity of Expression\n",
    "3. Emotional Tone Strength\n",
    "\n",
    "Respond in JSON like this:\n",
    "{{\n",
    "  \"conceptual_vocab_score\": 0.0,\n",
    "  \"clarity_score\": 0.0,\n",
    "  \"emotional_tone_score\": 0.0\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        result = client.chat.completions.create(\n",
    "            model=\"google/gemma-3n-e2b-it:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.4,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        content = result.choices[0].message.content.strip()\n",
    "        print(\"ðŸ” GEMMA RAW OUTPUT:\", content)\n",
    "\n",
    "        scores = json.loads(content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ Gemma scoring failed:\", e)\n",
    "        scores = {\n",
    "            \"conceptual_vocab_score\": 0.5,\n",
    "            \"clarity_score\": 0.5,\n",
    "            \"emotional_tone_score\": 0.5\n",
    "        }\n",
    "\n",
    "    # Optional: latency variability\n",
    "    if history and len(history) > 1:\n",
    "        previous_times = [s[\"time_taken\"] for s in history]\n",
    "        latency_std = round(statistics.stdev(previous_times), 2)\n",
    "    else:\n",
    "        latency_std = None\n",
    "\n",
    "    return {\n",
    "        \"conceptual_vocab_score\": scores[\"conceptual_vocab_score\"],\n",
    "        \"clarity_score\": scores[\"clarity_score\"],\n",
    "        \"emotional_tone_score\": scores[\"emotional_tone_score\"],\n",
    "        \"time_to_completion\": time_taken,\n",
    "        \"latency_variability\": latency_std\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a6d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "# Setup OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_followup_question(learning_goal):\n",
    "    prompt = f\"\"\"You are a motivational learning coach. A learner just said they want to learn: \"{learning_goal}\".\n",
    "\n",
    "Generate one open-ended, thoughtful question that will help them expand deeply on their personal motivation, challenges, or relationship to this topic. Be emotionally engaging and not too abstract.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        print(\"âœ… DeepSeek response received.\")\n",
    "        print(\"ðŸ”§ FULL RESPONSE:\", response)\n",
    "\n",
    "        content = response.choices[0].message.content.strip() if response.choices else \"\"\n",
    "        if not content:\n",
    "            print(\"âš ï¸ Empty content. Using fallback.\")\n",
    "            content = \"What does writing mean to you personally, and how do you want it to impact your future?\"\n",
    "\n",
    "        return content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ DeepSeek generation failed: {e}\")\n",
    "        return \"What inspires your desire to write, and what do you hope to express through it?\"\n",
    "\n",
    "def agent_one():\n",
    "    print(\"ðŸŽ¯ Welcome to the Adaptive Learning System (Prototype Agent 1)\")\n",
    "    learning_goal = input(\"ðŸ§  What are you trying to learn today?\\n> \")\n",
    "\n",
    "    # Generate personalized follow-up\n",
    "    followup_question = generate_followup_question(learning_goal)\n",
    "    print(f\"\\nðŸ” Reflect on this:\\n{followup_question}\\n\")\n",
    "\n",
    "    # Time response\n",
    "    start_time = time.time()\n",
    "    user_response = input(\"âœï¸ Your response:\\n> \")\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_taken = round(end_time - start_time, 2)\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    print(\"\\nðŸ•’ Time to respond:\", time_taken, \"seconds\")\n",
    "    print(\"ðŸ—“ï¸ Timestamp:\", timestamp)\n",
    "\n",
    "    return {\n",
    "        \"learning_goal\": learning_goal,\n",
    "        \"followup_question\": followup_question,\n",
    "        \"response\": user_response,\n",
    "        \"time_taken\": time_taken,\n",
    "        \"timestamp\": timestamp\n",
    "    }\n",
    "\n",
    "def analyze_response_gemma(response_text, time_taken, session_num, goal, history=None):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert language analyst. A learner wants to improve at: \"{goal}\".\n",
    "\n",
    "Here is their reflective response:\n",
    "\"{response_text}\"\n",
    "\n",
    "Evaluate on a 0â€“1 scale:\n",
    "1. Conceptual Vocabulary (depth, variety, originality)\n",
    "2. Clarity of Expression\n",
    "3. Emotional Tone Strength\n",
    "\n",
    "Respond in JSON like this:\n",
    "{{\n",
    "  \"conceptual_vocab_score\": 0.0,\n",
    "  \"clarity_score\": 0.0,\n",
    "  \"emotional_tone_score\": 0.0\n",
    "}}\n",
    "\"\"\"\n",
    "    try:\n",
    "        result = client.chat.completions.create(\n",
    "            model=\"google/gemma-3n-e2b-it:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.4,\n",
    "            max_tokens=200\n",
    "        )\n",
    "        print(\"ðŸ” FULL GEMMA RESPONSE OBJECT:\", result)\n",
    "        content = result.choices[0].message.content.strip()\n",
    "        print(\"ðŸ” GEMMA OUTPUT TEXT:\", content)\n",
    "        scores = json.loads(content)\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ Gemma scoring failed:\", e)\n",
    "        scores = {\n",
    "            \"conceptual_vocab_score\": 0.5,\n",
    "            \"clarity_score\": 0.5,\n",
    "            \"emotional_tone_score\": 0.5\n",
    "    }\n",
    "\n",
    "    # Compute latency variability if history exists\n",
    "    if history and len(history) > 1:\n",
    "        previous_times = [s[\"time_taken\"] for s in history]\n",
    "        latency_std = round(statistics.stdev(previous_times), 2)\n",
    "    else:\n",
    "        latency_std = None\n",
    "\n",
    "    return {\n",
    "        \"conceptual_vocab_score\": scores[\"conceptual_vocab_score\"],\n",
    "        \"clarity_score\": scores[\"clarity_score\"],\n",
    "        \"emotional_tone_score\": scores[\"emotional_tone_score\"],\n",
    "        \"time_to_completion\": time_taken,\n",
    "        \"latency_variability\": latency_std\n",
    "    }\n",
    "\n",
    "# Main runner\n",
    "if __name__ == \"__main__\":\n",
    "    history = []\n",
    "\n",
    "    result = agent_one()\n",
    "    analysis = analyze_response_gemma(\n",
    "        response_text=result[\"response\"],\n",
    "        time_taken=result[\"time_taken\"],\n",
    "        session_num=1,\n",
    "        goal=result[\"learning_goal\"],\n",
    "        history=history\n",
    "    )\n",
    "\n",
    "    print(\"\\nâœ… DATA CAPTURED:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\nðŸ“Š ANALYSIS SCORES:\")\n",
    "    for k, v in analysis.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    # Save to history (for future sessions)\n",
    "    history.append(result)\n",
    "\n",
    "\n",
    "# this works partly for what we want done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DeepSeek response received.\n",
      "ðŸ”§ FULL RESPONSE: ChatCompletion(id='gen-1752458931-K8twJo27lnp4ZE5HPDhy', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Okay, I understand you're\", refusal=None, role='assistant', function_call=None, tool_calls=None, reasoning=\"Okay, the user wants me to act as a motivational learning coach. Their query is a bit vague because they haven't specified what topic they want to learn. But they're asking me to create an open-ended, thoughtful question that will help them expand on their personal motivation, challenges, or relationship to this topic.\\n\\nI need to craft a question that's emotionally engaging and not too abstract. This means focusing on their personal experience and feelings about learning. Since they didn't specify the topic, I'll need to keep my response general enough to work for whatever topic they might be interested in.\\n\\nThe question should help them reflect deeply on why they want to learn something. I should focus on uncovering their intrinsic motivations and any potential barriers they might face. This will help me understand what truly drives them and what challenges they anticipate.\\n\\nI think I'll create a question that connects their desire to learn with something more personal - perhaps how it relates to their identity, their dreams, or their current challenges. This approach will help uncover deeper motivations and might reveal unspoken needs or aspirations they might not have initially articulated.\\n\\nThe question should be open-ended enough to encourage reflection while being specific enough to be meaningful. It should avoid being too abstract while still allowing for depth in their response.\\n\\nI'll craft a question that helps them connect the practical aspect of learning with the emotional and personal significance of it, which should provide valuable insight into their motivations and challenges regarding their learning journey.\\n\"), native_finish_reason='length')], created=1752458932, model='deepseek/deepseek-r1-0528-qwen3-8b:free', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=300, prompt_tokens=57, total_tokens=357, completion_tokens_details=None, prompt_tokens_details=None), provider='Chutes')\n",
      "\n",
      "ðŸ” Reflect on this:\n",
      "Okay, I understand you're\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this version of the code works really well, and is providing us with a decent feedback that should help with what we are trying ti figure. \n",
    "# -------- this version works. ----------------\n",
    "\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import statistics\n",
    "import re\n",
    "\n",
    "# Setup OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_followup_question(learning_goal):\n",
    "    prompt = f\"\"\"You are a motivational learning coach. A learner just said they want to learn: \"{learning_goal}\".\n",
    "\n",
    "Generate one open-ended, thoughtful question that will help them expand deeply on their personal motivation, challenges, or relationship to this topic. Be emotionally engaging and not too abstract.\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        print(\"âœ… DeepSeek response received.\")\n",
    "        print(\"ðŸ”§ FULL RESPONSE:\", response)\n",
    "\n",
    "        content = response.choices[0].message.content.strip() if response.choices else \"\"\n",
    "        if not content:\n",
    "            print(\"âš ï¸ Empty content. Using fallback.\")\n",
    "            content = \"What does writing mean to you personally, and how do you want it to impact your future?\"\n",
    "\n",
    "        return content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ DeepSeek generation failed: {e}\")\n",
    "        return \"What inspires your desire to write, and what do you hope to express through it?\"\n",
    "\n",
    "def agent_one():\n",
    "    print(\"ðŸŽ¯ Welcome to the Adaptive Learning System (Prototype Agent 1)\")\n",
    "    learning_goal = input(\"ðŸ§  What are you trying to learn today?\\n> \")\n",
    "\n",
    "    # Generate personalized follow-up\n",
    "    followup_question = generate_followup_question(learning_goal)\n",
    "    print(f\"\\nðŸ” Reflect on this:\\n{followup_question}\\n\")\n",
    "\n",
    "    # Time response\n",
    "    start_time = time.time()\n",
    "    user_response = input(\"âœï¸ Your response:\\n> \")\n",
    "    end_time = time.time()\n",
    "\n",
    "    time_taken = round(end_time - start_time, 2)\n",
    "    timestamp = datetime.now().isoformat()\n",
    "\n",
    "    print(\"\\nðŸ•’ Time to respond:\", time_taken, \"seconds\")\n",
    "    print(\"ðŸ—“ï¸ Timestamp:\", timestamp)\n",
    "\n",
    "    return {\n",
    "        \"learning_goal\": learning_goal,\n",
    "        \"followup_question\": followup_question,\n",
    "        \"response\": user_response,\n",
    "        \"time_taken\": time_taken,\n",
    "        \"timestamp\": timestamp\n",
    "    }\n",
    "\n",
    "def analyze_response_gemma(response_text, time_taken, session_num, goal, history=None):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert language analyst. A learner wants to improve at: \"{goal}\".\n",
    "\n",
    "Here is their reflective response:\n",
    "\"{response_text}\"\n",
    "\n",
    "Evaluate on a 0â€“1 scale:\n",
    "1. Conceptual Vocabulary (depth, variety, originality)\n",
    "2. Clarity of Expression\n",
    "3. Emotional Tone Strength\n",
    "\n",
    "Respond in JSON like this:\n",
    "{{\n",
    "  \"conceptual_vocab_score\": 0.0,\n",
    "  \"clarity_score\": 0.0,\n",
    "  \"emotional_tone_score\": 0.0\n",
    "}}\n",
    "\n",
    "Then write 1 sentence each explaining why the learner scored that way:\n",
    "- Conceptual Vocabulary: ...\n",
    "- Clarity: ...\n",
    "- Emotional Tone: ...\n",
    "\"\"\"\n",
    "    try:\n",
    "        result = client.chat.completions.create(\n",
    "            model=\"google/gemma-3n-e2b-it:free\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.4,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        raw_output = result.choices[0].message.content.strip()\n",
    "        print(\"ðŸ” GEMMA RAW OUTPUT:\", raw_output)\n",
    "\n",
    "        # Extract JSON\n",
    "        json_block = re.search(r\"\\{.*?\\}\", raw_output, re.DOTALL)\n",
    "        if json_block:\n",
    "            scores = json.loads(json_block.group(0))\n",
    "        else:\n",
    "            raise ValueError(\"Could not parse JSON block\")\n",
    "\n",
    "        # Extract explanation lines\n",
    "        explanations = {\n",
    "            \"conceptual_vocab_feedback\": \"Not found\",\n",
    "            \"clarity_feedback\": \"Not found\",\n",
    "            \"emotional_tone_feedback\": \"Not found\"\n",
    "        }\n",
    "        lines = raw_output.splitlines()\n",
    "        for line in lines:\n",
    "            if line.lower().startswith(\"- conceptual\"):\n",
    "                explanations[\"conceptual_vocab_feedback\"] = line.split(\":\", 1)[1].strip()\n",
    "            elif line.lower().startswith(\"- clarity\"):\n",
    "                explanations[\"clarity_feedback\"] = line.split(\":\", 1)[1].strip()\n",
    "            elif line.lower().startswith(\"- emotional\"):\n",
    "                explanations[\"emotional_tone_feedback\"] = line.split(\":\", 1)[1].strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ Gemma scoring failed:\", e)\n",
    "        scores = {\n",
    "            \"conceptual_vocab_score\": 0.5,\n",
    "            \"clarity_score\": 0.5,\n",
    "            \"emotional_tone_score\": 0.5\n",
    "        }\n",
    "        explanations = {\n",
    "            \"conceptual_vocab_feedback\": \"Default due to error.\",\n",
    "            \"clarity_feedback\": \"Default due to error.\",\n",
    "            \"emotional_tone_feedback\": \"Default due to error.\"\n",
    "        }\n",
    "\n",
    "    # Latency variability\n",
    "    if history and len(history) > 1:\n",
    "        previous_times = [s[\"time_taken\"] for s in history]\n",
    "        latency_std = round(statistics.stdev(previous_times), 2)\n",
    "    else:\n",
    "        latency_std = None\n",
    "\n",
    "    return {\n",
    "        **scores,\n",
    "        **explanations,\n",
    "        \"time_to_completion\": time_taken,\n",
    "        \"latency_variability\": latency_std\n",
    "    }\n",
    "\n",
    "# Main runner\n",
    "if __name__ == \"__main__\":\n",
    "    history = []\n",
    "\n",
    "    result = agent_one()\n",
    "    analysis = analyze_response_gemma(\n",
    "        response_text=result[\"response\"],\n",
    "        time_taken=result[\"time_taken\"],\n",
    "        session_num=1,\n",
    "        goal=result[\"learning_goal\"],\n",
    "        history=history\n",
    "    )\n",
    "\n",
    "    print(\"\\nâœ… DATA CAPTURED:\")\n",
    "    for k, v in result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\nðŸ“Š ANALYSIS SCORES:\")\n",
    "    for k in [\"conceptual_vocab_score\", \"clarity_score\", \"emotional_tone_score\"]:\n",
    "        print(f\"{k}: {analysis[k]}\")\n",
    "\n",
    "    print(\"\\nðŸ§  FEEDBACK:\")\n",
    "    for k in [\"conceptual_vocab_feedback\", \"clarity_feedback\", \"emotional_tone_feedback\"]:\n",
    "        label = k.replace(\"_feedback\", \"\").replace(\"_\", \" \").capitalize()\n",
    "        print(f\"- {label}: {analysis[k]}\")\n",
    "\n",
    "    history.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1dde4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9492867",
   "metadata": {},
   "source": [
    "## VERSION 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c291680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import ast\n",
    "\n",
    "# Set up OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\"  # Replace with your actual key\n",
    ")\n",
    "\n",
    "# STEP 1 ‚Äì Generate Task\n",
    "def generate_task(goal):\n",
    "    prompt = f\"\"\"\n",
    "The user is learning: \"{goal}\".\n",
    "Generate a short but meaningful persuasive or reflective writing task (3‚Äì5 sentences)\n",
    "that helps assess:\n",
    "- vocabulary use\n",
    "- curiosity\n",
    "- confidence\n",
    "- compression\n",
    "- emotional tone\n",
    "\n",
    "Return just the task instructions, not explanations.\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI tutor.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# STEP 2 ‚Äì Score User Response\n",
    "def score_response(goal, task, user_response):\n",
    "    prompt = f\"\"\"\n",
    "The user is learning: \"{goal}\"\n",
    "They were asked to complete this writing task: \"{task}\"\n",
    "They wrote the following:\n",
    "\n",
    "{user_response}\n",
    "\n",
    "Please rate them between 0.0 and 1.0 on:\n",
    "1. Vocabulary Expansion\n",
    "2. Curiosity\n",
    "3. Confidence\n",
    "4. Output Compression\n",
    "5. Emotional Consistency\n",
    "\n",
    "Return only a Python dictionary like:\n",
    "{{\"vocabulary_expansion_count\": ..., \"curiosity_level\": ..., \"confidence_level\": ..., \"output_compression_ratio\": ..., \"emotional_consistency_score\": ...}}\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI evaluator. Return only a Python dictionary.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return ast.literal_eval(response.choices[0].message.content)\n",
    "\n",
    "# STEP 3 ‚Äì Generate Feedback\n",
    "def give_feedback(goal, scores):\n",
    "    prompt = f\"\"\"\n",
    "The user is learning: \"{goal}\".\n",
    "Here are their scores:\n",
    "- Vocabulary Expansion Count: {scores['vocabulary_expansion_count']}\n",
    "- Curiosity Level: {scores['curiosity_level']}\n",
    "- Confidence Level: {scores['confidence_level']}\n",
    "- Output Compression Ratio: {scores['output_compression_ratio']}\n",
    "- Emotional Consistency Score: {scores['emotional_consistency_score']}\n",
    "\n",
    "Give:\n",
    "1. A natural explanation of their learning state\n",
    "2. Tailored guidance to help them improve in these areas\n",
    "3. Specific next-step exercises\n",
    "\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an encouraging but honest AI learning coach.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# ========== ‚úÖ RUN HERE ==========\n",
    "# Step 0 ‚Äì Enter Your Learning Goal\n",
    "goal = input(\"What are you trying to learn today? \")\n",
    "\n",
    "# Step 1 ‚Äì Generate a Personalized Task\n",
    "task = generate_task(goal)\n",
    "print(\"\\nüìù TASK FOR YOU TO COMPLETE:\\n\", task)\n",
    "\n",
    "# Step 2 ‚Äì Write Your Answer\n",
    "user_response = input(\"\\n‚úçÔ∏è Paste your answer here:\\n\")\n",
    "\n",
    "# Step 3 ‚Äì LLM Scores Your Work\n",
    "scores = score_response(goal, task, user_response)\n",
    "print(\"\\nüìä SCORES:\", scores)\n",
    "\n",
    "# Step 4 ‚Äì Get LLM-Powered Feedback\n",
    "feedback = give_feedback(goal, scores)\n",
    "print(\"\\nüí° FEEDBACK:\\n\", feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Setup client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\",  # Replace with your real key\n",
    ")\n",
    "\n",
    "# Core traits to evaluate\n",
    "traits = [\n",
    "    \"vocabulary_expansion_count\",\n",
    "    \"curiosity_level\",\n",
    "    \"confidence_level\",\n",
    "    \"output_compression_ratio\",\n",
    "    \"emotional_consistency_score\"\n",
    "]\n",
    "\n",
    "# Task generator (indirect prompt style)\n",
    "def generate_learning_task(goal):\n",
    "    writing_scenarios = [\n",
    "        \"Recall the last time you felt stuck while writing. What were you writing about, and what was holding you back?\",\n",
    "        \"Describe a time you had to convince someone to agree with you. How did you try to persuade them?\",\n",
    "        \"Write 3-5 sentences about a moment where you changed your opinion on something important. What led to the change?\",\n",
    "        \"Share a time when you had to write about something you didn‚Äôt care about. How did you try to make it work?\",\n",
    "        \"Reflect on the most rewarding piece of writing you've ever done. Why did it feel that way?\"\n",
    "    ]\n",
    "    return random.choice(writing_scenarios)\n",
    "\n",
    "# Trait scoring function\n",
    "def score_response(goal, task, response_text):\n",
    "    prompt = f\"\"\"You are a learning assessment AI. A student wants to get better at: \"{goal}\"\n",
    "\n",
    "They were given this task:\n",
    "\"{task}\"\n",
    "\n",
    "Here is their response:\n",
    "\"{response_text}\"\n",
    "\n",
    "Now rate their performance on the following traits from 0.0 to 1.0:\n",
    "\n",
    "1. vocabulary_expansion_count ‚Äì Variety and strength of vocabulary used.\n",
    "2. curiosity_level ‚Äì Depth of exploration and insight into the topic.\n",
    "3. confidence_level ‚Äì Strength and assertiveness of tone.\n",
    "4. output_compression_ratio ‚Äì Clarity and conciseness.\n",
    "5. emotional_consistency_score ‚Äì Stability and effectiveness of emotional tone.\n",
    "\n",
    "Return only a JSON object with the trait names as keys and scores as float values. Do NOT include any other explanation, markdown, or code formatting.\n",
    "\"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.4,\n",
    "        max_tokens=400\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # Attempt to extract and parse JSON directly\n",
    "        raw = completion.choices[0].message.content.strip()\n",
    "        return json.loads(raw)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"‚ö†Ô∏è Could not decode response:\", raw)\n",
    "        return None\n",
    "\n",
    "# Example use\n",
    "goal = input(\"What are you trying to learn today? \")\n",
    "task = generate_learning_task(goal)\n",
    "print(\"\\nüìù TASK FOR YOU TO COMPLETE:\")\n",
    "print(task)\n",
    "\n",
    "# Let the user enter response manually\n",
    "user_response = input(\"\\n‚úçÔ∏è Paste your answer here:\\n\")\n",
    "\n",
    "# Get scores\n",
    "scores = score_response(goal, task, user_response)\n",
    "\n",
    "# Display scores if successful\n",
    "if scores:\n",
    "    print(\"\\n--- METRIC SCORES ---\")\n",
    "    for trait, value in scores.items():\n",
    "        print(f\"{trait}: {value:.2f}\")\n",
    "else:\n",
    "    print(\"‚ùå Scoring failed. Please check formatting or try again.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
